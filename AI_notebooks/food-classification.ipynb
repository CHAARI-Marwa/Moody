{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":33884,"sourceType":"datasetVersion","datasetId":1864}],"dockerImageVersionId":30461,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport matplotlib.image as mpimg\nimport os.path\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-11T13:45:28.977006Z","iopub.execute_input":"2023-04-11T13:45:28.977411Z","iopub.status.idle":"2023-04-11T13:45:39.360202Z","shell.execute_reply.started":"2023-04-11T13:45:28.97737Z","shell.execute_reply":"2023-04-11T13:45:39.359055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating a directory\nimage_dir = Path('../input/food41/images')","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:45:39.362574Z","iopub.execute_input":"2023-04-11T13:45:39.363531Z","iopub.status.idle":"2023-04-11T13:45:39.369313Z","shell.execute_reply.started":"2023-04-11T13:45:39.36349Z","shell.execute_reply":"2023-04-11T13:45:39.367927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = sorted(os.listdir(image_dir))\nn_classes = len(class_names)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:45:39.371202Z","iopub.execute_input":"2023-04-11T13:45:39.371708Z","iopub.status.idle":"2023-04-11T13:45:39.401799Z","shell.execute_reply.started":"2023-04-11T13:45:39.37167Z","shell.execute_reply":"2023-04-11T13:45:39.400895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Discover names of all 101 food classes in the dataset\nprint(f\"Total Number of Classes : {n_classes} \\nClass Names : {class_names}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:45:39.404627Z","iopub.execute_input":"2023-04-11T13:45:39.40531Z","iopub.status.idle":"2023-04-11T13:45:39.41142Z","shell.execute_reply.started":"2023-04-11T13:45:39.405272Z","shell.execute_reply":"2023-04-11T13:45:39.410322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating File DataFrame","metadata":{}},{"cell_type":"code","source":"#creating a Pandas dataframe\nfilepaths = list(image_dir.glob(r'**/*.jpg'))\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n\nfilepaths = pd.Series(filepaths, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Label')\n\nimages = pd.concat([filepaths, labels], axis=1)\n\ncategory_samples = []\nfor category in images['Label'].unique():\n    category_slice = images.query(\"Label == @category\")\n    category_samples.append(category_slice.sample(100, random_state=1))\nimage_df = pd.concat(category_samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:45:39.414139Z","iopub.execute_input":"2023-04-11T13:45:39.414849Z","iopub.status.idle":"2023-04-11T13:46:10.335035Z","shell.execute_reply.started":"2023-04-11T13:45:39.414809Z","shell.execute_reply":"2023-04-11T13:46:10.334033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking how many photos are in each class - 100 as is expected\nimage_df['Label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:46:10.336559Z","iopub.execute_input":"2023-04-11T13:46:10.336922Z","iopub.status.idle":"2023-04-11T13:46:10.350328Z","shell.execute_reply.started":"2023-04-11T13:46:10.336885Z","shell.execute_reply":"2023-04-11T13:46:10.349297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display the first 10 images and their labels\nfig, axs = plt.subplots(2, 5, figsize=(10, 5))\naxs = axs.flatten()\n\nfor i in range(10):\n    img_name = image_df['Filepath'].iloc[i]\n    img_label = image_df['Label'].iloc[i]\n    \n    img = cv2.imread(img_name)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    axs[i].imshow(img)\n    axs[i].set_title(img_label)\n    axs[i].axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:46:10.35208Z","iopub.execute_input":"2023-04-11T13:46:10.35277Z","iopub.status.idle":"2023-04-11T13:46:11.25286Z","shell.execute_reply.started":"2023-04-11T13:46:10.352733Z","shell.execute_reply":"2023-04-11T13:46:11.250979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train-Test Split","metadata":{}},{"cell_type":"code","source":"#creating two image data generators - first one for train and validation datasets and the second one for test dataset\ntrain_df, test_df = train_test_split(image_df, train_size=0.7, shuffle=True, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:46:11.253922Z","iopub.execute_input":"2023-04-11T13:46:11.254243Z","iopub.status.idle":"2023-04-11T13:46:11.264376Z","shell.execute_reply.started":"2023-04-11T13:46:11.254211Z","shell.execute_reply":"2023-04-11T13:46:11.263007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n     rescale=1./255,\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:46:11.26639Z","iopub.execute_input":"2023-04-11T13:46:11.26728Z","iopub.status.idle":"2023-04-11T13:46:11.276515Z","shell.execute_reply.started":"2023-04-11T13:46:11.267242Z","shell.execute_reply":"2023-04-11T13:46:11.27524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setup dataset\n\ntrain_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)\n\nval_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)\n\ntest_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:46:11.281069Z","iopub.execute_input":"2023-04-11T13:46:11.281967Z","iopub.status.idle":"2023-04-11T13:46:15.712671Z","shell.execute_reply.started":"2023-04-11T13:46:11.281926Z","shell.execute_reply":"2023-04-11T13:46:15.711619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#defining a CNN using the MobileNetV2 architecture pre-trained on the ImageNet dataset\npretrained = tf.keras.applications.mobilenet_v2.MobileNetV2(\n    input_shape=[224,224,3], include_top=False, \n    weights='imagenet'\n    )\n\npretrained.trainable = False\n\nmodel = tf.keras.models.Sequential([\n    pretrained,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    layers.Dropout(0.25),\n    layers.Dense(256, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.1),\n    layers.Dense(128, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.1),\n    layers.Dense(n_classes, activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:46:15.713978Z","iopub.execute_input":"2023-04-11T13:46:15.714648Z","iopub.status.idle":"2023-04-11T13:46:20.449503Z","shell.execute_reply.started":"2023-04-11T13:46:15.714606Z","shell.execute_reply":"2023-04-11T13:46:20.448475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#let's configure the learning process using Adam optimizer and\n#look at the architecture of the model\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss=tf.keras.losses.CategoricalCrossentropy(),\n    metrics=[ 'AUC']\n)\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:46:20.451225Z","iopub.execute_input":"2023-04-11T13:46:20.4517Z","iopub.status.idle":"2023-04-11T13:46:20.520242Z","shell.execute_reply.started":"2023-04-11T13:46:20.451653Z","shell.execute_reply":"2023-04-11T13:46:20.519496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training the model with a batch size of 64 and saving the training history for further analysis\nEPOCHS = 50\nBATCH_SIZE = 64\nearly_stop = EarlyStopping(monitor='val_loss',min_delta=0.0001, patience=5, restore_best_weights = True)\nhistory2 = model.fit(train_images,\n                    steps_per_epoch=train_images.samples // BATCH_SIZE // 2,\n                    epochs=EPOCHS,\n                    validation_data=val_images,\n                    validation_steps= val_images.samples // BATCH_SIZE // 2,\n                    verbose=1,\n                    callbacks=[early_stop],\n                    shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:46:20.521299Z","iopub.execute_input":"2023-04-11T13:46:20.521945Z","iopub.status.idle":"2023-04-11T13:51:39.516217Z","shell.execute_reply.started":"2023-04-11T13:46:20.5219Z","shell.execute_reply":"2023-04-11T13:51:39.515196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#assessing the model's performance on the test dataset\nloss, auc = model.evaluate(test_images)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:51:39.517805Z","iopub.execute_input":"2023-04-11T13:51:39.518607Z","iopub.status.idle":"2023-04-11T13:52:18.83291Z","shell.execute_reply.started":"2023-04-11T13:51:39.518574Z","shell.execute_reply":"2023-04-11T13:52:18.831884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the available metrics\nhistory_dict2 = history2.history\n\nprint(history_dict2.keys())","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:52:18.834441Z","iopub.execute_input":"2023-04-11T13:52:18.834787Z","iopub.status.idle":"2023-04-11T13:52:18.840422Z","shell.execute_reply.started":"2023-04-11T13:52:18.834757Z","shell.execute_reply":"2023-04-11T13:52:18.839303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_train_instrumentation(epochs, data, train_param, val_param):\n    \n    plt.figure(figsize=(10,7))\n    \n    plt.plot(epochs, data[train_param], 'g', label=f'Training ({train_param})')\n    plt.plot(epochs, data[val_param], 'red', label=f'Validation ({val_param})')\n    \n    plt.title(\"Training performance\")\n    plt.xlabel('Epochs')\n    plt.ylabel(train_param)\n    \n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:52:18.842219Z","iopub.execute_input":"2023-04-11T13:52:18.842947Z","iopub.status.idle":"2023-04-11T13:52:18.853315Z","shell.execute_reply.started":"2023-04-11T13:52:18.842908Z","shell.execute_reply":"2023-04-11T13:52:18.852275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using the previously defined function to see the model's performance\n#the loss functions don't converge in one point at the end \n#there is a need to apply data augmentation or tune hypermarameters, but so far this is the best version we've been able to get\nepochs = range(1, len(history_dict2['auc'])+1)\n\nplot_train_instrumentation(epochs, history_dict2, 'auc', 'val_auc')\nplot_train_instrumentation(epochs, history_dict2, 'loss', 'val_loss')","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:52:18.856715Z","iopub.execute_input":"2023-04-11T13:52:18.857137Z","iopub.status.idle":"2023-04-11T13:52:19.399456Z","shell.execute_reply.started":"2023-04-11T13:52:18.857109Z","shell.execute_reply":"2023-04-11T13:52:19.398369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's generate a classification report for the predictions made by the trained model on the test dataset \n#to summarise the model's performance on each class\npredictions = np.argmax(model.predict(test_images), axis=1)\n\n\nreport = classification_report(test_images.labels, predictions, target_names=test_images.class_indices, zero_division=0)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:52:19.400986Z","iopub.execute_input":"2023-04-11T13:52:19.401725Z","iopub.status.idle":"2023-04-11T13:52:37.418942Z","shell.execute_reply.started":"2023-04-11T13:52:19.401678Z","shell.execute_reply":"2023-04-11T13:52:37.41767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#let's look at the report\n#the metrics vary between classes: the lowest F1 score is 0 for steak class and the highest is 0.97 for edamame class\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:52:37.42063Z","iopub.execute_input":"2023-04-11T13:52:37.421043Z","iopub.status.idle":"2023-04-11T13:52:37.42952Z","shell.execute_reply.started":"2023-04-11T13:52:37.421002Z","shell.execute_reply":"2023-04-11T13:52:37.428041Z"},"trusted":true},"execution_count":null,"outputs":[]}]}